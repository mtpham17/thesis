---
title: "Preliminary ELSA Machine Learnings Tests"
author: "Jonathan Seiden, Thu Pham"
date: "8/08/2022"
output: pdf_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo = TRUE)
library(readstata13)
library(tidyverse)
library(glmnet)
library(caret)
library(fastDummies)
library(glmmLasso)
knitr::opts_knit$set(root.dir = '/Users/thupham/Desktop/senior-yr/thesis/elsah-coptop')
# library(hrbrthemes)
# library(ggthemes)
# library(extrafont)
# library(remotes)
# remotes::install_version("Rttf2pt1", version = "1.3.8")
```

```{r}
#There are some issues with NA and NaN in the observation data that will mess up our analysis. We will replace these with mean (if numeric) and mode (if factor)

getmode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

replace.na <- function(var){
  ifelse(is.na(var) | is.nan(var), 
         ifelse(is.factor(var), getmode(var), mean(var, na.rm = TRUE)), var)
}

rmse <- function(predicted, true) {
  return(sqrt(sum((predicted - true)^2) / length(predicted)))
}

```



# Data consolidation process  

In this section, we process the data to get it into a format where each row is a child. 

## Child and Teacher Observation  
First we input the child and teacher observations and process them.

For each child in the COP data, we calculate:

1) The average for the child for each of the indicators across sweeps
2) The class average for each indicator *omitting* the child her/himself
3) The class standard deviation for each indicator *omitting* the child her/himself (only including children with 10 or more sweeps)

We then calculate the class average of the TOP indicators for the adults in the class by averaging across sweeps, and merge this data (one to many) with the child-level data. This merged data set contains XXX children in XXX classes




```{r y1_obs, warning=FALSE, cache=TRUE}
#Input the Year One long child and teacher observation data 
y1_child_obs_raw <- read.dta13("y1o_c_long.dta")
y1_teacher_obs_raw <- read.dta13("y1o_t_long.dta")
y1_coverpage_obs <- read.dta13("y1o_coverpage.dta")

#Re-format the child data so that it is one row per child

y1_child_obs <- y1_child_obs_raw %>%
  mutate(cid = ifelse(childid == "N/A", o_c_uniqueid, childid)) %>%
  group_by(cid, classid) %>%
  mutate(nsweeps = n()) %>%
  mutate_at(vars(o_c_verbal:o_c_focus), as.character) %>% 
  dplyr::select(c(classid, nsweeps, o_c_verbal:o_c_focus, 
                  starts_with("c_m8"), provid)) %>%
  # temporarily comment out this dummy generation so that we can test the VIF
  dummy_cols(select_columns = c("o_c_verbal", "o_c_towhom", "o_c_schedule", "o_c_interaction", "o_c_typetask", "o_c_involvement", "o_c_focus"),
             remove_selected_columns = TRUE) %>%
  group_by(classid, cid) %>%
  # replaced everything() with nsweeps:last_col()
  summarize(across(nsweeps:last_col(), ~ mean(.x, na.rm = TRUE))) %>%
  filter(nsweeps >= 10 ) %>% #THIS IS AN ARBITRARY PARAMETER
  group_by(classid) %>%
  mutate(nclass = n()) %>%
  # ifelse takes care of the case where there is only one student per class
  mutate(across(starts_with("o_c"), ~ 
                  (ifelse(get('nclass') == 1, .x, ((sum(.x, na.rm = TRUE) -.x) / 
                                                     get('nclass')))), .names = 
                  "{col}_classmean")) %>%
  mutate(across(starts_with("o_c") & !ends_with("classmean"), ~ 
                  (ifelse(get('nclass') == 1, 0, sqrt((sum((.x - get(str_c(cur_column(), 
                                                                           '_classmean')))^2) - 
                                                         (.x - get(str_c(cur_column(),
                                                                         '_classmean')))^2) / 
                                                        get('nclass')))), .names = 
                  "{col}_classsd")) %>%
  ungroup

#Re-format the teacher data so that it is one row per class
y1_teacher_obs <- y1_teacher_obs_raw %>% 
  dummy_cols(select_columns = c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o",
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o",
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o"),
             remove_selected_columns = TRUE) %>%
    group_by(classid) %>%
  summarize(
    nsweeps = n(),
    nadult = length(unique(o_t_uniqueid)),
    across(starts_with(c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                         "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                         "o_t_tone_o", "o_t_attention_o", "o_t_es_o", "m8")),
           ~ mean(.x, na.rm = TRUE))) %>%
  dplyr::select(-ends_with("_")) %>% 
  ungroup

#Merge teacher and child observations 
y1_obs <- left_join(y1_child_obs, y1_teacher_obs, by = "classid")

```

Below we now input the child-level outcome data. We focus on the outcomes that Emily suggested, and extract the year 1 and year 2 values for each child and then merge to create a single dataset. 

```{r child.outcomes, warning=FALSE, cache=TRUE}
#Get Year 1 and Year 2 child data
y1_child_outcomes_raw <- read.dta13("y1c.dta")
y2_child_outcomes_raw <- read.dta13("y2c.dta")

#Rename all y1 variables and y2 variables so we don't lose them when merging
y1_child_outcomes <-  y1_child_outcomes_raw %>% 
  dplyr::select(cid, c_mefs_str, c_pt_pcorrect, c_ltr_cogsoc_comp, c_ltr_emo_comp, 
         c_pra_total, c_pbsa_total, c_quils_total_raw, c_wjlw_str, c_wjap_str) %>% 
  rename_all( ~ paste0("y1_", .x)) %>% 
  mutate(cid = as.character(y1_cid))

y2_child_outcomes <-  y2_child_outcomes_raw %>% 
  dplyr::select(cid, c_mefs_str, c_pt_pcorrect, c_ltr_cogsoc_comp, c_ltr_emo_comp, 
         c_pbsa_allgrades_total, c_pra_allgrades_total, c_quils_total_raw, 
         c_wjlw_str, c_wjap_str, c_age_cat_test, c_age_test) %>% 
  rename(c_pra_total = c_pra_allgrades_total,
         c_pbsa_total = c_pbsa_allgrades_total) %>% 
  rename_all( ~ paste0("y2_", .x)) %>% 
  mutate(cid = as.character(y2_cid))

#Merge Y2 and Y1 data together and calculate the gain score for each of the outcomes
child_outcomes <- merge(y1_child_outcomes, y2_child_outcomes, by = "cid") %>% 
  mutate(gain_c_mefs_str = y2_c_mefs_str - y1_c_mefs_str, 
         gain_c_pt_pcorrect = y2_c_pt_pcorrect - y1_c_pt_pcorrect,  
         gain_c_ltr_cogsoc_comp = y2_c_ltr_cogsoc_comp - y1_c_ltr_cogsoc_comp,  
         gain_c_ltr_emo_comp = y2_c_ltr_emo_comp - y1_c_ltr_emo_comp, 
         gain_c_pra_total = y2_c_pra_total - y1_c_pra_total, 
         gain_c_pbsa_total = y2_c_pbsa_total - y1_c_pbsa_total, 
         gain_c_quils_total_raw = y2_c_quils_total_raw - y1_c_quils_total_raw, 
         gain_c_wjlw_str = y2_c_wjlw_str - y1_c_wjlw_str, 
         gain_c_wjap_str = y2_c_wjap_str - y1_c_wjap_str,
         cid = as.numeric(cid))

```

Finally, we merge together the Year 1 observation data with the Year 1 & 2 child outcome data and add in care type. We omit observations that have no classroom observation resulting in a total analytic dataframe of 1169 observations of 64 variables. 

```{r merge.obs.outcomes y1 p1, cache=TRUE}
#Merge in the outcomes data 
y1_obs <- y1_obs %>%
  filter(!is.na(cid)) %>%
  mutate(cid = as.numeric(cid))

outcomes_and_obs_y1 <- left_join(child_outcomes, y1_obs, by = "cid") %>% 
  mutate(cid = as.character(cid))

#Add in the care type
caretype <- read.dta13("y1caretype.dta") %>% 
  mutate(cid = as.character(cid))

#Remove observations that have no care type or no classroom observation
outcomes_and_obs_full_y1 <- left_join(outcomes_and_obs_y1, caretype, by = "cid") %>% 
  mutate(hasobservation = is.na(classid)) %>% 
  filter(!is.na(caretype)) %>%
  filter(!is.na(classid))

# outcomes_and_obs_full_y1 <- outcomes_and_obs %>% 
#   filter(!is.na(classid))

#Remove Y1 and Y2 data for cleanliness
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  dplyr::select(-starts_with(c("y1", "y2")))

#Remove some irrelevant variables and rename columns with 
#illegal spaces
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  dplyr::select(-c(famid, dob:dob_uncertain, actual_fcc:hasobservation)) %>% 
  mutate(caretype = as.factor(caretype),
         actualtype = as.factor(actualtype),
         provid = as.factor(provid)) %>% 
  rename_at(vars(everything()), ~str_replace_all(., "\\s+", "")) %>%
  rename_at(vars(everything()), ~str_replace_all(., ",", "")) %>%
  rename_at(vars(everything()), ~str_replace_all(., "\\(", "_")) %>%
  rename_at(vars(everything()), ~str_replace_all(., "\\)", "")) %>%
  rename_at(vars(everything()), ~str_replace_all(., "-|:|/", "."))
```
Notes for simulation: 
- There are 294 total columns in `outcomes_and_obs_full_y1'. 
- There are 8 gain variables.
- There are "magic 8" goals, but I don't think there are actually 8 of them? There are currently 5 of the "m8," and 5 of the "c_m8" (class averages or sums?)
- For the child, there are 34 `o_c' variables. 
- For the teacher, there are 33 `o_t' variables. Obviously, both of these categorical variables will expand by a lot when we use dummy variables and compute the class means and standard deviations.
- We are going to choose one gain variable to work with, the one that has the most total correlation (so most "representative?") -- should also try to maybe do some PCA? There can be two separate analyses with these methods.

```{r}
gain_ind <- which(startsWith(colnames(outcomes_and_obs_full_y1), "gain"))
```

```{r}
# filter out clusters that only have one observation
outcomes_and_obs_full_y1_largec <-  outcomes_and_obs_full_y1 %>%
    group_by(provid) %>%
    filter(n() > 1) %>%
    droplevels() %>%
    ungroup
```


```{r outcomes_corrplot, echo=TRUE, fig.height=8, cache=TRUE}
res <- cor(outcomes_and_obs_full_y1_largec[, gain_ind],
           use="complete.obs")
# invert correlation matrix; the diagonal elements give us the correlation of that outcome to the rest of the outcomes: http://www2.tulane.edu/~PsycStat/dunlap/Psyc613/RI2.html#:~:text=The%20Inverted%20Correlation%20Matrix%20%2D%2D&text=When%20the%20measures%20are%20correlated,volume%20is%20less%20than%201.&text=Therefore%2C%20the%20diagonal%20elements%20allow,other%20variables%20in%20the%20set.

inv <-solve(res)
diag(inv)
outcomes_use_y1 <- colnames(outcomes_and_obs_full_y1_largec)[gain_ind][order(diag(inv))[1:3]]

# results: "gain_c_mefs_str" "gain_c_wjlw_str" "gain_c_wjap_str" --> 
# MEFS Z-score, WJ Letter Word ID, WJ Applied Problems
# Minnesota Executive Function Scale (MEFSTM) is a standardized assessment of EF skills designed
# for children ages 2 and up with child-friendly graphics, avatars, and child-directed instructions
# executive function --> self control
```


```{r merge.obs.outcomes y1 p2, cache=TRUE}

# names(outcomes_and_obs_full_y1)
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  mutate_at(vars(c_m8_goal_1:actualtype), replace.na)

dim(outcomes_and_obs_full_y1)

```

## Analysis


```{r}
# for preliminary empirical results, thesis
#TODO 2/28: need to figure out why I did this weird standardization thing

outcomes <- colnames(outcomes_and_obs_full_y1[, gain_ind])
models_y1_use <- list()
coefficients_model_y1_use <- list()
for (outcome in outcomes_use_y1) {
  other_outcomes <- outcomes[outcomes != outcome]
  df_analysis <- outcomes_and_obs_full_y1 %>%
    filter(!is.na(outcomes_and_obs_full_y1[[outcome]])) %>%
    # make sure to not use cid, because it's basically just the row number at this point
    dplyr::select(-c(other_outcomes, cid))
  allSd <- apply(df_analysis[, -1], 2, sd)
  var.names <- colnames(df_analysis)[-c(1, which(colnames(df_analysis) == "provid"))]
  # var.names <- var.names[1:10]
  formula <- as.formula(paste(outcome, "~", paste(var.names, collapse= " + ")))
  x = model.matrix(formula, data = df_analysis)
  
  y = df_analysis[[outcome]]
  x = x[, -1]
  

  # call cv.glmnet()
  model_lasso <- cv.glmnet(x = x, y = y, alpha = 1)
  # plot(model_lasso)
  
  models_y1_use[[outcome]] <- model_lasso
  cc_y1_use = coef(model_lasso, s = model_lasso$lambda.min)
  print(model_lasso$lambda.min)

  # print out the model coefficients and store in a list.
  # exclude the intercept
  cc_y1_use = cc_y1_use[cc_y1_use[,1]!=0,1][-1]
  # remove backticks for ease of standardizing
  names(cc_y1_use)<- gsub("`","", names(cc_y1_use))
  coefficients_model_y1_use[[outcome]] <- cc_y1_use * allSd[names(cc_y1_use)]
  # print(cc)

}

## THESE ARE THE COEFFICIENTS FOR Y1: coefficients_model_y1_use
```


```{r}
outcome <- outcomes_use_y1[1]
other_outcomes <- outcomes[outcomes != outcome]

cv_glmmLasso <- function(data, formula, rand=list(j=~1),
                      lambda_step=10, lambda_min = lambda_min,
                      lambda_max = lambda_max, kk=5) {
  lambdas <- seq(lambda_min, lambda_max, length = lambda_step)
  
  N <- dim(data)[1]
  ind <- sample(N, N)
  
  # number of folds
  
  nk <- floor(N/kk)
  
  pred_error <- matrix(NA, ncol=kk, nrow = lambda_step)

  
  for (j in 1:lambda_step) {
    print("one lambda")
    for (i in 1:kk)
    {
      if (i < kk) {
      indi <- ind[(i-1)*nk+(1:nk)]
      }
      else {
      indi <- ind[((i-1)*nk+1):N]
      }
  
    data_train <- data[-indi,]
    data_test <-data[indi,]
  
    glm <- glmmLasso(fix = formula, rnd = rand, data = data_train, 
              lambda = lambdas[j])
            
        # if(!inherits(glm, "try-error"))
        # {  
          y_hat <- predict(glm, data_test)  
          pred_error[j,i]<- sqrt(sum((data_test[outcome] - 
                                        y_hat)^2) / nrow(data_test))
        # }
        
        # else 
        # {
          # return("error in choosing lambda value")
        # }
    }
  }
  
  # find lambda which gives lowest prediction error
  pred_error_vec <- apply(pred_error, 1, sum)
  print(pred_error_vec)
  return(lambdas[which.min(pred_error_vec)])  
}
```



```{r}
lambda_range <- function(data, formula, p,
                         baseline_min_lambda = 10^(-2),
                         baseline_max_lambda = 10^3,
                         lambda_no = 20) {
    
    lambdas <- seq(baseline_min_lambda, baseline_max_lambda, length = lambda_no)
    min_lambda <- baseline_min_lambda
    max_lambda <- baseline_max_lambda
    coefs <- rep(0, lambda_no)
    
    for (l in 1:length(lambdas)) {
      print(lambdas[l])
      mixed_lasso <- glmmLasso(fix = formula,
                           rnd=list(provid=~1),
                           data = data,
                           lambda = lambdas[l],
                           final.re = TRUE)
      
      coefs[l] <- sum(mixed_lasso$coefficients[2:(p + 1)] != 0)
      print(coefs[l])
                             
    }
    
    min_lambda <- ifelse(length(which(coefs == p)) == 0, 
                         baseline_min_lambda,
                         lambdas[max(which(coefs == p))])
    max_lambda <- ifelse(length(which(coefs == 0)) == 0,
                         baseline_max_lambda,
                         lambdas[min(which(coefs == 0))])
    return(c(min_lambda, max_lambda))
}
```



```{r}
library(caret)
perf_metrics <- function(beta_hat, beta_true, y_hat, y_true, default, fixed) {
  
  y_rmse <- rmse(y_hat, y_true)
  
  beta_rmse <- rmse(beta_hat, beta_true)
  
  # rewrite beta values as 0 (less than default / 2) and 1 (greater than default)
  # anything in between is "indifferent?" can we just have anything greater than 
  # default / 2 as TRUE?
  
  true_beta_categorical <- factor(beta_true > default / 2, 
                                  levels = levels(factor(c(TRUE, FALSE))))
  pred_beta_categorical <- factor(beta_hat > default / 2, 
                                  levels = levels(factor(c(TRUE, FALSE))))
  
  cm <- confusionMatrix(pred_beta_categorical, true_beta_categorical,
                mode = "everything",
                positive="TRUE")
  
  # previously, true positive/negative
  sensitivity <- unname(cm$byClass["Sensitivity"])
  specificity <- unname(cm$byClass["Specificity"])
  precision <- unname(cm$byClass["Precision"])
  recall <- unname(cm$byClass["Recall"])
  f <- unname(cm$byClass["F1"])
  
  results_list <- list(y_rmse, beta_rmse, sensitivity, specificity, 
                       precision, recall, f)
  names <- c("y_rmse", "beta_rmse", "sensitivity", "specificity", 
             "precision", "recall", "F1")
  if (fixed) {
    names(results_list) <- unlist(lapply(names, function(x) paste(x, "_fixed", 
                                                                  sep = "")))
  }
  
  else {
    names(results_list) <- unlist(lapply(names, function(x) paste(x, "_mixed", 
                                                                  sep = "")))
  }
  
  return(results_list)
}
```

# see brainstorming in scratch_data_work.Rmd -- decided on some pre-processing with LASSO 0.1 and then removing columns with pairwise correlation greater than 0.95

```{r}
# takes in data frame of "row", "col", "var"

lasso_coefs <- function(raw_data) {
  
  all_vars <- colnames(raw_data)[! (colnames(raw_data) 
                                              %in% c("provid", outcome))]
  options(na.action="na.pass")
  x = model.matrix(as.formula(paste(outcome, "~ . -provid")), 
                   data = raw_data)
  
  y = raw_data[[outcome]]
  x = x[, -1]
  model_lasso <- glmnet(x = x, y = y, lambda = 0.01)
  coefs_for_glm <- coef(model_lasso)
  coefs_for_glm <- names(coefs_for_glm[coefs_for_glm[, 1] != 0, 1][-1])
  
  return(coefs_for_glm)
  
}

freq_table_helper <- function(high_corr) {
  freq_table <- as.data.frame(high_corr %>%
    group_by(row) %>%
    summarize(count = n()) %>%
    ungroup())
  
  return(freq_table)
}

cor_matrix_helper <- function(df_analysis_noncor, cor_value) {

  cor_matrix <- cor(as.matrix(df_analysis_noncor))
  cor_1 <- which(cor_matrix > cor_value, arr.ind = TRUE)
  cor_df <- as.data.frame(cor_1)
  cor_df$variables <- rownames(cor_1)
  rownames(cor_df) <- NULL
  high_corr <- unique(cor_df[cor_df$row != cor_df$col, ])
  
  return(high_corr)
  
}

corr_matrix_processing <- function(df_analysis_noncor, threshold = 8,
                                   cor_value) {
  high_corr <- cor_matrix_helper(df_analysis_noncor, cor_value)
  freq_table <- freq_table_helper(high_corr)
  
  while(max(freq_table$count) > threshold)
  {
    index_to_eliminate <- which.max(freq_table$count)
    row_to_eliminate <- freq_table[index_to_eliminate, "row"]
    high_corr_var <- high_corr[row_to_eliminate, "variables"]
    # print(high_corr_var)
    df_analysis_noncor <- df_analysis_noncor %>% 
      dplyr::select(-high_corr_var)
    high_corr <- cor_matrix_helper(df_analysis_noncor, cor_value)
    freq_table <- freq_table_helper(high_corr)
  }
  
  return(high_corr)
}

# test <- corr_matrix_processing(df_analysis_noncor, cor_value = 0.60)
```


```{r}

data_processing <- function(data, cor_value, method = FALSE) {
  print(ncol(data))
  ### first, run data through low regularization parameter
  coefs_for_glm <- lasso_coefs(raw_data = data)
  print(length(coefs_for_glm))

  df_analysis_noncor <- data %>%
    dplyr::select(c(coefs_for_glm, outcome))
  
  # print(c(coefs_for_glm, outcome))
  print(ncol(df_analysis_noncor))
  print("finished first step")
  
  # df_analysis_noncor_nonzero <- df_analysis_noncor
  
  ### second, delete any columns that are simply a constant (zero SD)
  df_analysis_noncor_numeric <- df_analysis_noncor %>%
    select_if(is.numeric)

  zero_sd <- apply(select_if(df_analysis_noncor_numeric,
                             is.numeric), 2, function(x) sd(x) == 0 |
                     sum(x) < 1)
  zero_sd_cols <- colnames(select_if(df_analysis_noncor_numeric,
                                     is.numeric))[zero_sd]
  print(zero_sd_cols)
  df_analysis_noncor_nonzero <- df_analysis_noncor_numeric %>%
    dplyr::select(-all_of(zero_sd_cols))
  all_numeric_vars <- colnames(df_analysis_noncor_nonzero)[-1]

  print(ncol(df_analysis_noncor_nonzero))
  print("finished second step")
  
  
  ## third, remove all data that has high pairwise correlation (defined by 
  ## correlation value and "threshold")
  high_corr <- corr_matrix_processing(df_analysis_noncor_nonzero,
                                      cor_value = cor_value)
  high_cor_variables <- high_corr$variables
  # print(vars_to_remove)
  df_analysis_lowcor <- df_analysis_noncor_nonzero %>%
    dplyr::select(-high_cor_variables) 
  
  print(ncol(df_analysis_lowcor))
  print("finished third step")
  
  
  ## finally, remove all columns that create linear combination
  
  linear_combos <- findLinearCombos(df_analysis_lowcor)$remove
  linear_vars <- names(df_analysis_lowcor)[linear_combos]
  
  # modify df_analysis_noncor to get final data frame (that includes 
  # provid, for example)
  df_analysis_noncor_nonlinear <- data %>%
    dplyr::select(c(all_of(coefs_for_glm), "provid", outcome)) %>%
    dplyr::select(-c(all_of(linear_vars), all_of(zero_sd_cols),
                     all_of(high_cor_variables)))
  print(ncol(df_analysis_noncor_nonlinear))
  print("finished fourth step")
  
  return(df_analysis_noncor_nonlinear)
}

raw_full_data <- outcomes_and_obs_full_y1 %>%
filter(!is.na(outcomes_and_obs_full_y1[[outcome]])) %>%
dplyr::select(-c(all_of(other_outcomes), caretype, classid, 
                 cid, nsweeps.y,
                 actualtype, nsweeps.x)) %>%
  drop_na()
df_analysis_largec <- as.data.frame(data_processing(raw_full_data,
                                      cor_value = 0.95))
```

## try 2-fold cross validation to see if this fixes the rank issue

```{r}

x = model.matrix(as.formula(paste(outcome, "~ . - provid")), 
                   data = df_analysis_largec)
  
y = df_analysis_largec[[outcome]]
x = x[, -1]

coefs_for_glm <- head(colnames(df_analysis_largec), -2)
formula <- as.formula(paste(outcome, "~", paste(coefs_for_glm, 
                                              collapse = " + ")))

fixed_lasso <- cv.glmnet(x = x, y = y, alpha = 1, type.measure = "mse")
coefs_fixed <- coef(fixed_lasso, s = "lambda.min")[-1]
nonzero_coefs_fixed <- which(coefs_fixed != 0)
nonzero_coefs_fixed <- coefs_for_glm[nonzero_coefs_fixed]

l_range <- lambda_range(df_analysis_largec, formula, length(coefs_for_glm))
best_lambda <- cv_glmmLasso(df_analysis_largec, formula,
                            rand = list(provid = ~1),
                            lambda_step = 20, lambda_min = l_range[1],
                            lambda_max = l_range[2], kk = 5)
mixed_lasso <- glmmLasso(data = df_analysis_largec, fix = formula, 
                         rnd = list(provid=~1), lambda = best_lambda)
coefs_mixed <- mixed_lasso$coefficients[-1]
nonzero_coefs_mixed <- names(coefs_mixed[coefs_mixed != 0])

agreement <- sum((coefs_fixed == 0 & coefs_mixed == 0) | 
                   (coefs_fixed != 0 & coefs_mixed != 0)) / length(coefs_for_glm)

```

## exploring data to understand what kind of simulation to run

```{r}
coefs <- summary(lm(as.formula(paste(outcome, "~ . - provid")),
   data = df_analysis_largec, na.action = na.exclude))$coefficients

coefs_df <- as.data.frame(coefs)

p1 <- ggplot(coefs_df, mapping = aes(x = Estimate)) +
  geom_histogram(color = "black", fill = "#FF9999") +   
  ggtitle("Histogram of Coefficients from Basic Linear Regression") +
  ylab("Frequency") + 
  xlab("Coefficients from Basic Linear Regression") + 
  theme(plot.title = element_text(hjust = 0.5))

p1
ggsave("/Users/thupham/Desktop/thesis/plots/linear_reg_coefs.png")


  # hist(coefs_df$Estimate)

p2 <- ggplot(coefs_df[coefs_df$Estimate < 20 & coefs_df$Estimate > -20, ],
             mapping = aes(x = Estimate)) +
  geom_histogram(color = "black", fill = "#FF9999") +
  ggtitle("Histogram of Most Coefficients from Basic Linear Regression") +
  ylab("Frequency") +
  xlab("Coefficients from Basic Linear Regression (Between -10 and 10)") +
  theme(plot.title = element_text(hjust = 0.5))
# looks like beta type 4 with some scaling? default = 50?

p2
ggsave("/Users/thupham/Desktop/thesis/plots/linear_reg_coefs_zoom.png")

# generate_data(n_bar, J, alpha, 
#                     type, p, s, default,
#                     cov_x, scale, base_mean_x = 0, sigma_x = 1, 
#                     mean_r = 0, sigma_r, 
#                     snr,
#                     mean_noise = 0, sigma_noise = 1)

clusters <- df_analysis_largec %>% group_by(provid) %>% summarize(n = n()) %>% ungroup()


p3 <- ggplot(clusters,
             mapping = aes(x = n)) +
  geom_histogram(color = "black", fill = "#FF9999") +
  ggtitle("Histogram of Size of Clusters") +
  ylab("Frequency") +
  xlab("Cluster Size") +
  theme(plot.title = element_text(hjust = 0.5))

p3 
ggsave("/Users/thupham/Desktop/thesis/plots/cluster_size.png")

nrow(clusters)
# J = 232 --> let's round this down to 50 for now lol
mean(clusters$n)
# n_bar = 3
var(clusters$n)
var(clusters$n[clusters$n < 6])
# alpha = 1/3?

ggplot(data = df_analysis_largec, 
       mapping = aes(y = nclass)) +
  geom_histogram()

r2 <- summary(lm(as.formula(paste(outcome, "~ . - provid")),
   data = df_analysis_largec, na.action = na.exclude))$r.squared
# r squared value is 0.315
snr <- r2 / (1 - r2)
# snr value is 0.458766

# there are so many clusters? just assume scale = 1 for now...

# 220 predictors.
# round down to 110?

cor <- cor(as.matrix(select_if(df_analysis, is.numeric)))
std <- apply(select_if(df_analysis, is.numeric), 2, 
             function(x) sqrt(var(x)))
cov <- cor * std * cor
(sum(cov[1, ], na.rm = TRUE) - 1) / ncol(select_if(df_analysis,
                                                   is.numeric))
# cov_x = -0.0004
```


- type 4
- p = 110
- s = 7
- default = 50
- cov_x = -0.0004
- scale = 1?
- snr = 0.46




