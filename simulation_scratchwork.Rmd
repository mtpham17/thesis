---
title: "simulation_scratchwork"
output: pdf_document
date: '2023-01-12'
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/thupham/Desktop/thesis')
library(readstata13)
library(tidyverse)
library(glmnet)
library(caret)
library(fastDummies)
library(mvtnorm)
library(dplyr)
library(glmnet)
library(glmmLasso)
library(future)
library(furrr)
```


```{r}
# cross validation helper function for the glmmLasso

library(MASS)
library(nlme)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

# https://rdrr.io/cran/glmmLasso/src/demo/glmmLasso-soccer.r
cv_glmmLasso <- function(data, formula, rand=list(j=~1),
                      lambda_step=20, lambda_min = lambda_min,
                      lambda_max = lambda_max) {
  lambdas <- seq(lambda_min, lambda_max, length = lambda_step)
  
  N <- dim(data)[1]
  ind <- sample(N, N)
  
  # number of folds
  
  kk <- 5
  nk <- floor(N/kk)
  
  pred_error <- matrix(NA, ncol=kk, nrow = lambda_step)

  
  for (j in 1:lambda_step) {
    for (i in 1:kk)
    {
      if (i < kk) {
      indi <- ind[(i-1)*nk+(1:nk)]
      }
      else {
      indi <- ind[((i-1)*nk+1):N]
      }
  
    data_train <- data[-indi,]
    data_test <-data[indi,]
  
    glm <- try(glmmLasso(fix = formula, rnd = rand, data = data_train, 
              lambda = lambdas[j]), silent = TRUE) 
            
        if(!inherits(glm, "try-error"))
        {  
          y_hat <- predict(glm, data_test)  
          pred_error[j,i]<- sqrt(sum((data_test$Y - y_hat)^2) / nrow(data_test))
        }
        
        else 
        {
          return("error in choosing lambda value")
        }
    }
  }
  
  # find lambda which gives lowest prediction error
  pred_error_vec <- apply(pred_error, 1, sum)
  return(lambdas[which.min(pred_error_vec)])  
}

## other suggestion (haven't implemented this): run a simulation with a lot of lambdas, get a range of lambdas that we consistently see across these simulations. restrict the range based on those results
```

```{r}
# beta generator function, following Trevor Hastie, Robert Tibshirani, Ryan Tibshirani

# type = one of c(1, 2, 3, 5) -- to specify the type of beta vector we will have.
# p = number of predictors (also the number of betas)
# s = number of beta's that follow the setup given in the paper
# default = value that the s components take on

# beta-type 1: \beta's have s components equal to (default), occurring at (roughly) equal spaced indices between 1 and p, and the rest equal to 0
# beta-type 2: \beta has its first s components equal to 1, and the rest equal to 0
# beta-type 3: \beta has its first s components, taking nonzero values equally spaced between 10 and 0.5, and the rest equal to 0
# added back in beta-type 4 (the Ryan paper excluded it because they got similar results, but I'm running a slightly different simulation): \beta has its first s components, taking nonzero values equally spaced between -10 and 10, and the rest equal to 0 
# beta-type 5: \beta has its first s components equal to 1, and the rest decaying exponentially to 0, specifically \beta_i = 0.5^{i - s}, for i = s + 1, ..., p

generate_beta <- function(type, p, s, default = 1) {
  if (s > p) {
    s <- p
  }
  
  if (type == 1) {
    # create roughly spaced indices, we want s betas to have a value of 1
    indices <- seq(1, p, length.out = s)
    betas <- rep(0, p)
    betas[indices] <- 1
    return(betas)
  }
  
  if (type == 2) {
    return(c(rep(default, s), rep(0, p - s)))
  }
  
  if (type == 3) {
    return(c(seq(-10, 0.5, length.out = s), 
             rep(0, p - s)))
  }
  
  if (type == 4) {
    return(c(seq(-10, 10, length.out = s), 
             rep(0, p - s)))

  }
  
  if (p == s) {
    return(c(rep(default, s)))
  }
  
  return(c(rep(default, s), 0.5^seq(s + 1, p)))
}
```

```{r rmse}
rmse <- function(predicted, true) {
  return(sqrt(sum((predicted - true)^2) / length(predicted)))
}
```


```{r sample_size}
sample_size_gen <- function(n_bar, alpha, J) {
  n_min <- round(n_bar * (1 - alpha))
  n_max <- round(n_bar * (1 + alpha))
  sample_size <- sample(n_min:n_max, J, replace = TRUE)
  if (n_min == n_max) {
    sample_size <- rep(n_bar, J)
  }
  return(sample_size)
}
```

```{r generate_data, warnings=FALSE}

## DESCRIPTION OF INPUTS
# type, p, s, default are all the arguments that are taken in by generate_beta
# cov_x = covariance between covariates
# mean_x = mean of covariates
# sigma_x = standard deviation of covariate distribution
# mean_r = mean of random intercepts
# sigma_r = standard deviation of random intercepts

generate_data <- function(n_bar, J, alpha, 
                          type, p, s, default,
                          cov_x, scale, base_mean_x = 0, sigma_x = 1, 
                          mean_r = 0, sigma_r, 
                          snr, mean_noise = 0, sigma_noise = 1) {
  
  # generate sizes of each cluster 
  sample_size <- sample_size_gen(n_bar = n_bar, alpha = alpha, J = J)
  n <- sum(sample_size)
  
  colnames_df <- c(paste("X", 1:p, sep = ""), "random_beta") 
  r_b <- rnorm(n = J, mean = mean_r, sigma_r)
  random_beta <- rep(r_b, times = sample_size)
  
  fixed_beta <- generate_beta(type, p, s, default)
  
  sigma <- diag(sigma_x^2 - cov_x, p, p) + matrix(cov_x, nrow = p, ncol = p)
  mean_x <- matrix(rep(scale * random_beta, p), nrow = n, ncol = p)
  x_all <- rmvnorm(n = n, mean = rep(base_mean_x, p), sigma)
  
  # decided to scrap this, and add a whole matrix of means instead (repeated across columns)
  # Cholesky decomposition to generate correlated covariates
  # c <- chol(sigma)
  # x_unc <- replicate(p, rnorm(n, mean_x))
  # x_all <- x_unc %*% c
  
  x_all <- mean_x + x_all
  measurement_noise <- rmvnorm(n = n, mean = rep(mean_noise, p), 
                               diag(sigma_noise^2, p, p))
  noisy_x <- x_all + measurement_noise
  
  data <- as.data.frame(cbind(noisy_x, random_beta))
  colnames(data) <- colnames_df
  
  # error term 
  epsilon <- rnorm(n)
  
  # now, relaxing the assumption of how strong our measures are. per Luke's suggestion,
  # add the noise into the covariates so that we preserve the structure from earlier.
  
  data$Y <- rowSums(sweep(x_all, 2, fixed_beta, "*")) + random_beta + epsilon
  print(data$Y)
  
  # 02/13/23: adding signal to noise for more insightful graphs
  
  k <- sqrt(var(data$Y)/(snr*var(epsilon)))
  print(k)
  data$Y = data$Y + k*epsilon 
  
  # 02/13/23: adding signal to noise for more insightful graphs
  
  k <- sqrt(var(data$Y)/(snr*var(epsilon)))
  data$Y = data$Y + k*epsilon 
  
  data$j <- as.factor(rep(1:J, times = sample_size))
  
  return(data)
}

test_df <- generate_data(n_bar = 50, J = 4, alpha = 0.8,
  type = 1, p = 10, s = 3, default = 1,
  cov_x = 0.5, scale = 1, base_mean_x = 0, sigma_x = 1,
  mean_r = 0, sigma_r = 1,
  snr = 1,
  mean_noise = 0, sigma_noise = 1)

```


```{r}
# finding range of lambdas to feed into cv_glmmLasso later
# current rationale is that min lambda should be value of lambda such that no variables are eliminated, and the max lambda is value such that all variables are eliminated

# need to figure out what the baseline values of lambda are 
lambda_range <- function(data, p, baseline_min_lambda = 10^(-2), baseline_max_lambda = 10^3,
                         lambda_no = 100) {
    
    var.names <- paste("X", 1:p, sep = "")
    com.names <- lapply(seq_along(var.names),
                        function(i) combn(var.names, i, FUN = paste, collapse = " + "))
    covariates <- com.names[[p]]
    
    lambdas <- seq(baseline_min_lambda, baseline_max_lambda, length = lambda_no)
    min_lambda <- baseline_min_lambda
    max_lambda <- baseline_max_lambda
    coefs <- rep(0, lambda_no)
    
    for (l in 1:length(lambdas)) {
      mixed_lasso <- glmmLasso(fix = as.formula(paste("Y ~", covariates)),
                           rnd=list(j=~1),
                           data = data,
                           lambda = lambdas[l],
                           final.re = TRUE)
      
      coefs[l] <- sum(mixed_lasso$coefficients[2:(p + 1)] != 0)
                             
    }
    min_lambda <- ifelse(length(which(coefs == p)) == 0, 
                         baseline_min_lambda,
                         lambdas[max(which(coefs == p))])
    max_lambda <- ifelse(length(which(coefs == 0)) == 0,
                         baseline_max_lambda,
                         lambdas[min(which(coefs == 0))])
    return(c(min_lambda, max_lambda))
}

lambda_range(test_df, 10)
```

```{r}
library(caret)
perf_metrics <- function(beta_hat, beta_true, y_hat, y_true, fixed) {
  
  y_rmse <- rmse(y_hat, y_true)
  
  beta_rmse <- rmse(beta_hat, beta_true)
  
  # rewrite beta values as 0 (equal to zero) and 1 (nonzero)
  
  true_beta_categorical <- factor(beta_true != 0, levels = levels(factor(c(TRUE, FALSE))))
  pred_beta_categorical <- factor(beta_hat != 0, levels = levels(factor(c(TRUE, FALSE))))
  
  cm <- confusionMatrix(pred_beta_categorical, true_beta_categorical,
                mode = "everything",
                positive="TRUE")
  
  # previously, true positive/negative
  sensitivity <- unname(cm$byClass["Sensitivity"])
  specificity <- unname(cm$byClass["Specificity"])
  precision <- unname(cm$byClass["Precision"])
  recall <- unname(cm$byClass["Recall"])
  f <- unname(cm$byClass["F1"])
  
  results_list <- list(y_rmse, beta_rmse, sensitivity, specificity, precision, recall, f)
  names <- c("y_rmse", "beta_rmse", "sensitivity", "specificity", "precision", "recall", "F1")
  if (fixed) {
    names(results_list) <- unlist(lapply(names, function(x) paste(x, "_fixed", sep = "")))
  }
  
  else {
    names(results_list) <- unlist(lapply(names, function(x) paste(x, "_mixed", sep = "")))
  }
  
  return(results_list)
}
```


```{r}
# Analyze
analyze <- function(data, p, true_beta) {
  var.names <- paste("X", 1:p, sep = "")
  com.names <- lapply(seq_along(var.names),
                    function(i) combn(var.names, i, FUN = paste, collapse = " + "))
  covariates <- com.names[[p]]
  
  X_fixed <- model.matrix(as.formula(paste("Y ~", covariates)),
                          data = data)
  X_fixed <- X_fixed[, -1]

  model_lasso_fixed <- cv.glmnet(x = X_fixed, y = data$Y, nfolds = 5, alpha = 1)
  coefficients_fixed <- coef(model_lasso_fixed, s = 
                               model_lasso_fixed$lambda.min)[2:(length(true_beta) + 1)]
  
  lambda_range <- lambda_range(data, p)
  
  best_lambda <- cv_glmmLasso(data = data,
                             formula = as.formula(paste("Y ~", covariates)), 
                             lambda_min = lambda_range[1], lambda_max = lambda_range[2])
  model_lasso_mixed <- glmmLasso(fix = as.formula(paste("Y ~", covariates)),
                                 rnd=list(j=~1),
                                 data = data,
                                 lambda=best_lambda,
                                 final.re = TRUE)
  
  coefficients_mixed <- model_lasso_mixed$coefficients[2:(length(true_beta) + 1)]

  
  basic_linear <- lm(as.formula(paste("Y ~", covariates)), data = data)
  
  # "the two models agreed on ___ percent of the covariates" -- agreement defined as they both 
  # deemed a beta as non-zero out of the total significant betas. 
  
  agreement <- sum((coefficients_fixed != 0 & coefficients_mixed != 0) |
                  (coefficients_fixed == 0 & coefficients_mixed == 0)) / p
  
  y_hat_fixed <- predict(model_lasso_fixed, newx = X_fixed, s = model_lasso_fixed$lambda.min)
  y_hat_mixed <- predict(model_lasso_mixed, newx = X_fixed, s = lambda_min)
  
  fixed_results <- perf_metrics(coefficients_fixed, true_beta, y_hat_fixed, data$Y, TRUE)
  mixed_results <- perf_metrics(coefficients_mixed, true_beta, y_hat_mixed, data$Y, FALSE)
  
  # TODO 1/9: consider adding intra and inter-cluster variation, as well as variation (variance?) 
  # explained, alongside the adjusted r squared
  
  return(c(list("adj_r_squared" = summary(basic_linear)$adj.r.squared, "agreement" = agreement), 
           fixed_results,
           mixed_results))
}

test_beta <- generate_beta(1, 5, 3)
results <- analyze(test_df, 5, test_beta)

```


```{r}
# Repeat

one_run <- function(n_bar, J, alpha, 
                    type, p, s, default,
                    cov_x, scale, base_mean_x = 0, sigma_x = 1, 
                    mean_r = 0, sigma_r,
                    snr,
                    mean_noise = 0, sigma_noise = 1) {
  
  data <- generate_data(n_bar, J, alpha, 
                    type, p, s, default,
                    cov_x, scale, base_mean_x = 0, sigma_x = 1, 
                    mean_r = 0, sigma_r, 
                    snr,
                    mean_noise = 0, sigma_noise = 1)
  
  fixed_beta <- generate_beta(type, p, s, default)
  result <- analyze(data, p, fixed_beta)
  return(result)
}

# if you keep getting weird results with the simulation, email dataset and short script to groll@statistik.tu-dortmund.de
```


```{r}
rerun_single_params <- function(chunkNo, seed, reps,
                           n_bar, J, alpha,
                           type, p, s, default, cov_x,
                           scale, base_mean_x, sigma_x,
                           mean_r, sigma_r, 
                           snr, mean_noise, sigma_noise) {
  print("starting an iteration")
  set.seed(seed)
  results <- rerun(reps, one_run(n_bar = n_bar, J = J,
                                       alpha = alpha,
                                       type = type, p = p,
                                       s = s, default = default,
                                       cov_x = cov_x, scale = scale,
                                       base_mean_x = base_mean_x,
                                       sigma_x = sigma_x,
                                       mean_r = mean_r, sigma_r = sigma_r,
                                        snr = snr,
                                       mean_noise = mean_noise,
                                       sigma_noise = sigma_noise))
  
  results_length <- length(results[[1]])
  
  mean_results <- sapply(1:results_length, 
                         function(j) mean(unlist(lapply(results, function(x) x[j]))))
  sd_results <- sapply(1:results_length, 
                         function(j) sd(unlist(lapply(results, function(x) x[j]))))
  
  row <- c(chunkNo, seed, reps, n_bar, J, alpha,
           type, p, s, default, cov_x, scale, base_mean_x, sigma_x,
           mean_r, sigma_r, snr, mean_noise, sigma_noise, mean_results, sd_results)
  
  names(row) <- c("chunkNo", "seed", "reps", "n_bar", "J", "alpha",
                  "type", "p", "s", "default", "cov_x", "scale", "base_mean_x", "sigma_x",
                  "mean_r", "sigma_r", "snr", "mean_noise", "sigma_noise", 
                  unname(sapply(names(results[[1]]), function(x) paste("mean_", x, sep = ""))),
                  unname(sapply(names(results[[1]]), function(x) paste("sd_", x, sep = ""))))

  return(row)
}
```

```{r}
# source("pack_simulation_functions.R")
safe_run_sim = safely(rerun_single_params)
file_saving_sim = function(chunkNo, seed, reps,
                           n_bar, J, alpha,
                           type, p, s, default, cov_x,
                           scale, base_mean_x, sigma_x,
                           mean_r, sigma_r, snr,
                           mean_noise, sigma_noise) 
  {
    # fname = paste0("/Users/thupham/Desktop/thesis/results/", chunkNo, "_", seed, ".csv")
    fname = paste0("/n/home04/thupham17/thesis/results/021323_run/", 
               chunkNo, "_", seed, ".csv")
    res = NA
    if (!file.exists(fname)) {
        res <- safe_run_sim(chunkNo = chunkNo, seed = seed, reps = reps,
                           n_bar = n_bar, J = J, alpha = alpha,
                           type = type, p = p, s = s, default = default, cov_x = cov_x,
                           scale = scale, base_mean_x = base_mean_x, sigma_x = sigma_x,
                           mean_r = mean_r, sigma_r = sigma_r, snr = snr, 
                           mean_noise = mean_noise, 
                           sigma_noise = sigma_noise)
        res <- as.data.frame(t(res$result))
        write.csv(res, fname)
        print(res)
    } else {
        res = read.csv(file = fname)
    }
    return(res)
}
```

```{r}
options(warn=-1)

R <- 1000
M_CHUNK <- 50

params <- expand.grid(chunkNo = 1:M_CHUNK,
                      n_bar = 50,
                      J = 5,
                      alpha = 0.5,
                      type = 1:5,
                      p = 12,
                      s = 4,
                      default = 1,
                      cov_x = 0.25,
                      scale = 1,
                      base_mean_x = 0,
                      sigma_x = 1,
                      mean_r = 0,
                      sigma_r = 2,
<<<<<<< HEAD
                      snr = seq(0.1, 1.1, by = 0.2),
=======
                      snr = seq(0, 1, by = 0.2),
>>>>>>> 6036f61a742a720237205d0359e14670407f5060
                      mean_noise = 0,
                      sigma_noise = 1)

# before snr:

# params <- expand.grid(chunkNo = 1:M_CHUNK,
#                       n_bar = seq(20, 80, by = 20),
#                       J = 5,
#                       alpha = seq(0, 1, by = 0.25),
#                       type = 1:5,
#                       p = seq(8, 20, by = 4),
#                       s = 4,
#                       default = 1,
#                       cov_x = 0.25,
#                       scale = seq(0, 4, by = 1),
#                       base_mean_x = 0,
#                       sigma_x = 1,
#                       mean_r = 0,
#                       sigma_r = 2,
#                       mean_noise = 0,
#                       sigma_noise = 1)


params <- params %>% mutate(
    reps = R / M_CHUNK,
    seed = 17 + 1:n()
)
```

<<<<<<< HEAD

```{r}
sink("/n/home04/thupham17/thesis/logs/output_021323.txt")
=======
sink("/n/home04/thupham17/thesis/logs/output_020723.txt")
>>>>>>> 6036f61a742a720237205d0359e14670407f5060
# sink("/Users/thupham/Desktop/thesis/results/output.txt")

print("VARYING SCALE AND TYPE")
print(params)

tictoc::tic("10 iterations one set")

if (TRUE) {
    # Run in parallel
    
    library(future)
    library(furrr)
  
    plan(multisession, workers = parallel::detectCores() - 2)
    
    results <- future_pmap(params, .f = file_saving_sim,
                          .options = furrr_options(seed = NULL),
                          .progress = TRUE)
    
    plan(sequential)
    
} else {
  # Run not in parallel, used for debugging
  params$res <- pmap(params, .f = file_saving_sim)
}

Sys.sleep(1)
tictoc::toc()

sink()
# 10 iterations one set: 19.772 sec elapsed, with 6 cores?? 
# 10 iterations one set: 20.74 sec elapsed, with 46 cores??
```

```{r}
concat_files <- function(pathname) {
  setwd(pathname)
  for (data in list.files()){
  
  # Create the first data if no data exist yet
    if (!exists("dataset")){
      dataset <- read.csv(data, header=TRUE)
    }
    
    # if data already exist, then append it together
    if (exists("dataset")){
      tempory <-read.csv(data, header=TRUE)
      dataset <-unique(rbind(dataset, tempory))
      rm(tempory)
    }
  }
  return(dataset)
}
```

```{r}
# source: https://michaelinom.medium.com/how-to-combine-all-csv-files-from-the-same-folder-into-one-data-frame-automatically-with-r-1775876a876c
pathname <- "/n/home04/thupham17/thesis/results/021323_run"
if (TRUE) {
    # Run in parallel
    
    library(future)
    library(furrr)
  
    plan(multisession, workers = parallel::detectCores() - 2)
    
    dataset <- future_pmap(pathname, .f = concat_files,
                          .options = furrr_options(seed = NULL),
                          .progress = TRUE)
    
    plan(sequential)
    
} else {
  # Run not in parallel, used for debugging
  dataset <- pmap(pathname, .f = concat_files)
}

write.csv(dataset[[1]], "/n/home04/thupham17/thesis/concat_results/021323_run.csv")
```


```{r}
# options(warn=-1)
# set.seed(17)
# 
# prelim_results <- rerun_mult_parameters(runs_vec = 100, 
#                                         n_bar_vec = seq(from = 20, to = 100, by = 20),
#                                         J_vec = seq(from = 2, to = 10, by = 2), 
#                                         alpha_vec = seq(from = 0, to = 1, 
#                                                         by = 0.25),
#                                         type_vec = 1:5,
#                                         p_vec = seq(from = 2, to = 20, by = 6), 
#                                         s_vec = seq(from = 1, to = 20, by = 6), 
#                                         default_vec = 1,
#                                         cov_x = seq(from = 0, to = 6, by = 3),
#                                         scale_vec = seq(from = 0, to = 6, by = 3),
#                                         base_mean_x_vec = 0, 
#                                         sigma_x_vec = 1,
#                                         mean_r_vec = 0, 
#                                         sigma_r_vec = seq(from = 0, to = 4, by = 2),
#                                         mean_noise_vec = 0, 
#                                         sigma_noise_vec = 1)
```

```{r}
# results <- assess_performance(prelim_results)
# write.csv(results, "/n/home04/thupham17/fasrc/results.csv")
```

```{r}
# Profiling R Code
# to profile code with system time method, etc.

# quickadd <- function(g){
# *return(g+1)*
# *}*
# 
# *slowadd <- function(g){*
# *h <- rep(NA, length(g))*
# *for (i in 1:length(g)){*
# *h[i] <- g[i] + 1*
# *}*
# *return(h)*
# *}*
# 
# *system.time(a <- slowadd(g))*
# user system elapsed
# 0.34 0.00 0.34
# 
# *system.time(a <- quickadd(g))*
# user system elapsed
# 0 0 0

#code
```
