---
title: "Preliminary ELSA Machine Learnings Tests"
author: "Jonathan Seiden, Thu Pham"
date: "8/08/2022"
output: pdf_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo = TRUE)
library(readstata13)
library(tidyverse)
library(glmnet)
library(caret)
library(fastDummies)
library(glmmLasso)
knitr::opts_knit$set(root.dir = '/Users/thupham/Desktop/senior-yr/thesis/elsah-coptop')
# library(hrbrthemes)
# library(ggthemes)
# library(extrafont)
# library(remotes)
# remotes::install_version("Rttf2pt1", version = "1.3.8")
```

```{r}
#There are some issues with NA and NaN in the observation data that will mess up our analysis. We will replace these with mean (if numeric) and mode (if factor)

getmode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

replace.na <- function(var){
  ifelse(is.na(var) | is.nan(var), 
         ifelse(is.factor(var), getmode(var), mean(var, na.rm = TRUE)), var)
}
```
# Data consolidation process  

In this section, we process the data to get it into a format where each row is a child. 

## Child and Teacher Observation  
First we input the child and teacher observations and process them.

For each child in the COP data, we calculate:

1) The average for the child for each of the indicators across sweeps
2) The class average for each indicator *omitting* the child her/himself
3) The class standard deviation for each indicator *omitting* the child her/himself (only including children with 10 or more sweeps)

We then calculate the class average of the TOP indicators for the adults in the class by averaging across sweeps, and merge this data (one to many) with the child-level data. This merged data set contains XXX children in XXX classes


```{r y1_obs, warning=FALSE, cache=TRUE}
#Input the Year One long child and teacher observation data 
y1_child_obs_raw <- read.dta13("y1o_c_long.dta")
y1_teacher_obs_raw <- read.dta13("y1o_t_long.dta")
y1_coverpage_obs <- read.dta13("y1o_coverpage.dta")

#Re-format the child data so that it is one row per child

y1_child_obs <- y1_child_obs_raw %>%
  mutate(cid = ifelse(childid == "N/A", o_c_uniqueid, childid)) %>%
  group_by(cid, classid) %>%
  mutate(nsweeps = n()) %>%
  mutate_at(vars(o_c_verbal:o_c_focus), as.character) %>% 
  dplyr::select(c(classid, nsweeps, o_c_verbal:o_c_focus, 
                  starts_with("c_m8"), provid)) %>%
  # temporarily comment out this dummy generation so that we can test the VIF
  dummy_cols(select_columns = c("o_c_verbal", "o_c_towhom", "o_c_schedule", "o_c_interaction", "o_c_typetask", "o_c_involvement", "o_c_focus"),
             remove_selected_columns = TRUE) %>%
  group_by(classid, cid) %>%
  # replaced everything() with nsweeps:last_col()
  summarize(across(nsweeps:last_col(), ~ mean(.x, na.rm = TRUE))) %>%
  filter(nsweeps >= 10 ) %>% #THIS IS AN ARBITRARY PARAMETER
  group_by(classid) %>%
  mutate(nclass = n()) %>%
  # ifelse takes care of the case where there is only one student per class
  mutate(across(starts_with("o_c"), ~ 
                  (ifelse(get('nclass') == 1, .x, ((sum(.x, na.rm = TRUE) -.x) / 
                                                     get('nclass')))), .names = 
                  "{col}_classmean")) %>%
  mutate(across(starts_with("o_c") & !ends_with("classmean"), ~ 
                  (ifelse(get('nclass') == 1, 0, sqrt((sum((.x - get(str_c(cur_column(), 
                                                                           '_classmean')))^2) - 
                                                         (.x - get(str_c(cur_column(),
                                                                         '_classmean')))^2) / 
                                                        get('nclass')))), .names = 
                  "{col}_classsd")) %>%
  ungroup

#Re-format the teacher data so that it is one row per class
y1_teacher_obs <- y1_teacher_obs_raw %>% 
  dummy_cols(select_columns = c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o",
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o",
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o"),
             remove_selected_columns = TRUE) %>%
    group_by(classid) %>%
  summarize(
    nsweeps = n(),
    nadult = length(unique(o_t_uniqueid)),
    across(starts_with(c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                         "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                         "o_t_tone_o", "o_t_attention_o", "o_t_es_o", "m8")),
           ~ mean(.x, na.rm = TRUE))) %>%
  dplyr::select(-ends_with("_")) %>% 
  ungroup

#Merge teacher and child observations 
y1_obs <- left_join(y1_child_obs, y1_teacher_obs, by = "classid")

```

```{r}
table(y1_teacher_obs$nadult)
```


```{r y2_obs, warning=FALSE, cache=TRUE}
#Input the Year One long child and teacher observation data 
y2_child_obs_raw <- read.dta13("y2o_c_long.dta")
y2_teacher_obs_raw <- read.dta13("y2o_t_long.dta")
y2_coverpage_obs <- read.dta13("y2o_coverpage.dta")

mean(y2_coverpage_obs$classid %in% y1_coverpage_obs$classid)

#Re-format the child data so that it is one row per child
y2_child_obs <- y2_child_obs_raw %>%
 mutate(cid = ifelse(cid == "N/A", o_c_uniqueid, cid)) %>%
  group_by(cid, classid) %>%
  mutate(nsweeps = n()) %>%
  mutate_at(vars(o_c_verbal:o_c_focus), as.character) %>% 
  dplyr::select(c(classid, nsweeps, o_c_verbal:o_c_focus, starts_with("c_m8"))) %>%
  dummy_cols(select_columns = c("o_c_verbal", "o_c_towhom", "o_c_schedule", "o_c_interaction", "o_c_typetask", "o_c_involvement", "o_c_focus"),
             remove_selected_columns = TRUE) %>% 
  group_by(classid, cid) %>%
  # replaced everything() with nsweeps:last_col()
  summarize(across(nsweeps:last_col(), ~ mean(.x, na.rm = TRUE))) %>%
  filter(nsweeps >= 10 ) %>% #THIS IS AN ARBITRARY PARAMETER
  group_by(classid) %>%
  mutate(nclass = n()) %>%
    # ifelse takes care of the case where there is only one student per class
  mutate(across(starts_with("o_c"), ~ 
                  (ifelse(get('nclass') == 1, .x, ((sum(.x, na.rm = TRUE) -.x) / 
                                                     get('nclass')))), .names = 
                  "{col}_classmean")) %>%
  mutate(across(starts_with("o_c") & !ends_with("classmean"), ~ 
                  (ifelse(get('nclass') == 1, 0, sqrt((sum((.x - get(str_c(cur_column(), 
                                                                           '_classmean')))^2) - 
                                                         (.x - get(str_c(cur_column(),
                                                                         '_classmean')))^2) / 
                                                        get('nclass')))), .names = 
                  "{col}_classsd")) %>%
  ungroup

#Re-format the teacher data so that it is one row per class
y2_teacher_obs <- y2_teacher_obs_raw %>% 
  dummy_cols(select_columns = c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o"),
             remove_selected_columns = TRUE) %>% 
    group_by(classid) %>%
  summarize(
    nsweeps = n(),
    nadult = length(unique(o_t_uniqueid)),
    across(starts_with(c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                         "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                         "o_t_tone_o", "o_t_attention_o", "o_t_es_o", "m8")),
            ~ mean(.x, na.rm = TRUE))) %>%
  dplyr::select(-ends_with("_")) %>% 
  ungroup

#Extract the caretype from the observation sheet
## ASK -- what is meant by this?

#Merge teacher and child observations 
y2_obs <- left_join(y2_child_obs, y2_teacher_obs, by = "classid")
y2_obs <- y2_obs %>% 
  rename_at(vars(everything()), ~str_replace_all(., "\\s+", ""))

```


Below we now input the child-level outcome data. We focus on the outcomes that Emily suggested, and extract the year 1 and year 2 values for each child and then merge to create a single dataset. 

```{r child.outcomes, warning=FALSE, cache=TRUE}
#Get Year 1 and Year 2 child data
y1_child_outcomes_raw <- read.dta13("y1c.dta")
y2_child_outcomes_raw <- read.dta13("y2c.dta")

#Rename all y1 variables and y2 variables so we don't lose them when merging
y1_child_outcomes <-  y1_child_outcomes_raw %>% 
  dplyr::select(cid, c_mefs_str, c_pt_pcorrect, c_ltr_cogsoc_comp, c_ltr_emo_comp, 
         c_pra_total, c_pbsa_total, c_quils_total_raw, c_wjlw_str, c_wjap_str) %>% 
  rename_all( ~ paste0("y1_", .x)) %>% 
  mutate(cid = as.character(y1_cid))

y2_child_outcomes <-  y2_child_outcomes_raw %>% 
  dplyr::select(cid, c_mefs_str, c_pt_pcorrect, c_ltr_cogsoc_comp, c_ltr_emo_comp, 
         c_pbsa_allgrades_total, c_pra_allgrades_total, c_quils_total_raw, 
         c_wjlw_str, c_wjap_str, c_age_cat_test, c_age_test) %>% 
  rename(c_pra_total = c_pra_allgrades_total,
         c_pbsa_total = c_pbsa_allgrades_total) %>% 
  rename_all( ~ paste0("y2_", .x)) %>% 
  mutate(cid = as.character(y2_cid))

#Merge Y2 and Y1 data together and calculate the gain score for each of the outcomes
child_outcomes <- merge(y1_child_outcomes, y2_child_outcomes, by = "cid") %>% 
  mutate(gain_c_mefs_str = y2_c_mefs_str - y1_c_mefs_str, 
         gain_c_pt_pcorrect = y2_c_pt_pcorrect - y1_c_pt_pcorrect,  
         gain_c_ltr_cogsoc_comp = y2_c_ltr_cogsoc_comp - y1_c_ltr_cogsoc_comp,  
         gain_c_ltr_emo_comp = y2_c_ltr_emo_comp - y1_c_ltr_emo_comp, 
         gain_c_pra_total = y2_c_pra_total - y1_c_pra_total, 
         gain_c_pbsa_total = y2_c_pbsa_total - y1_c_pbsa_total, 
         gain_c_quils_total_raw = y2_c_quils_total_raw - y1_c_quils_total_raw, 
         gain_c_wjlw_str = y2_c_wjlw_str - y1_c_wjlw_str, 
         gain_c_wjap_str = y2_c_wjap_str - y1_c_wjap_str,
         cid = as.numeric(cid))

```

Finally, we merge together the Year 1 observation data with the Year 1 & 2 child outcome data and add in care type. We omit observations that have no classroom observation resulting in a total analytic dataframe of 1169 observations of 64 variables. 

```{r merge.obs.outcomes y1 p1, cache=TRUE}
#Merge in the outcomes data 
y1_obs <- y1_obs %>%
  filter(!is.na(cid)) %>%
  mutate(cid = as.numeric(cid))

outcomes_and_obs_y1 <- left_join(child_outcomes, y1_obs, by = "cid") %>% 
  mutate(cid = as.character(cid))

#Add in the care type
caretype <- read.dta13("y1caretype.dta") %>% 
  mutate(cid = as.character(cid))

#Remove observations that have no care type or no classroom observation
outcomes_and_obs_full_y1 <- left_join(outcomes_and_obs_y1, caretype, by = "cid") %>% 
  mutate(hasobservation = is.na(classid)) %>% 
  filter(!is.na(caretype)) %>%
  filter(!is.na(classid))

# outcomes_and_obs_full_y1 <- outcomes_and_obs %>% 
#   filter(!is.na(classid))

#Remove Y1 and Y2 data for cleanliness
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  dplyr::select(-starts_with(c("y1", "y2")))

#Remove some irrelevant variables and rename columns with 
#illegal spaces
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  dplyr::select(-c(famid, dob:dob_uncertain, actual_fcc:hasobservation)) %>% 
  mutate(caretype = as.factor(caretype),
         actualtype = as.factor(actualtype),
         provid = as.factor(provid)) %>% 
  rename_at(vars(everything()), ~str_replace_all(., "\\s+", "")) %>%
  rename_at(vars(everything()), ~str_replace_all(., ",", "")) %>%
  rename_at(vars(everything()), ~str_replace_all(., "\\(", "_")) %>%
  rename_at(vars(everything()), ~str_replace_all(., "\\)", "")) %>%
  rename_at(vars(everything()), ~str_replace_all(., "-|:|/", "."))
```
Notes for simulation: 
- There are 294 total columns in `outcomes_and_obs_full_y1'. 
- There are 8 gain variables.
- There are "magic 8" goals, but I don't think there are actually 8 of them? There are currently 5 of the "m8," and 5 of the "c_m8" (class averages or sums?)
- For the child, there are 34 `o_c' variables. 
- For the teacher, there are 33 `o_t' variables. Obviously, both of these categorical variables will expand by a lot when we use dummy variables and compute the class means and standard deviations.
- We are going to choose one gain variable to work with, the one that has the most total correlation (so most "representative?") -- should also try to maybe do some PCA? There can be two separate analyses with these methods.



```{r}
gain_ind <- which(startsWith(colnames(outcomes_and_obs_full_y1), "gain"))
# for (i in gain_ind) {
#   df_analysis <- outcomes_and_obs_full_y1[!is.na(outcomes_and_obs_full_y1[, i]), ]
#   print(colnames(outcomes_and_obs_full_y1)[i])
#   print(cor.test(as.numeric(df_analysis$classid), 
#      as.numeric(df_analysis[, i])))
#   test <- chisq.test(table(as.numeric(df_analysis$classid), 
#                            df_analysis[, i]))
#   print(test)
# }

```

```{r}
# filter out clusters that only have one observation
outcomes_and_obs_full_y1_largec <-  outcomes_and_obs_full_y1 %>%
    group_by(provid) %>%
    filter(n() > 1) %>%
    droplevels() %>%
    ungroup
```


```{r outcomes_corrplot, echo=TRUE, fig.height=8, cache=TRUE}
res <- cor(outcomes_and_obs_full_y1_largec[, gain_ind],
           use="complete.obs")
# invert correlation matrix; the diagonal elements give us the correlation of that outcome to the rest of the outcomes: http://www2.tulane.edu/~PsycStat/dunlap/Psyc613/RI2.html#:~:text=The%20Inverted%20Correlation%20Matrix%20%2D%2D&text=When%20the%20measures%20are%20correlated,volume%20is%20less%20than%201.&text=Therefore%2C%20the%20diagonal%20elements%20allow,other%20variables%20in%20the%20set.

inv <-solve(res)
diag(inv)
outcomes_use_y1 <- colnames(outcomes_and_obs_full_y1_largec)[gain_ind][order(diag(inv))[1:3]]

# results: "gain_c_mefs_str" "gain_c_wjlw_str" "gain_c_wjap_str" --> 
# MEFS Z-score, WJ Letter Word ID, WJ Applied Problems
# Minnesota Executive Function Scale (MEFSTM) is a standardized assessment of EF skills designed
# for children ages 2 and up with child-friendly graphics, avatars, and child-directed instructions
# executive function --> self control
```


```{r merge.obs.outcomes y1 p2, cache=TRUE}

# names(outcomes_and_obs_full_y1)
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  mutate_at(vars(c_m8_goal_1:actualtype), replace.na)

# what is o_t_sched_t supposed to be for? replacing with actualtype for now just to run analysis

# replacing all NaNs in hopes that it will fix the model matrix issue
# originally was o_c_verbal_talk:o_t_sched_t

dim(outcomes_and_obs_full_y1)

```

## Analysis


```{r}
# for preliminary empirical results, thesis
outcomes <- colnames(outcomes_and_obs_full_y1[, gain_ind])
models_y1_use <- list()
coefficients_model_y1_use <- list()
for (outcome in outcomes_use_y1) {
  other_outcomes <- outcomes[outcomes != outcome]
  df_analysis <- outcomes_and_obs_full_y1 %>%
    filter(!is.na(outcomes_and_obs_full_y1[[outcome]])) %>%
    # make sure to not use cid, because it's basically just the row number at this point
    select(-c(other_outcomes, cid))
  allSd <- apply(df_analysis[, -1], 2, sd)
  var.names <- colnames(df_analysis)[-c(1, which(colnames(df_analysis) == "provid"))]
  # var.names <- var.names[1:10]
  formula <- as.formula(paste(outcome, "~", paste(var.names, collapse= " + ")))
  x = model.matrix(formula, data = df_analysis)
  
  y = df_analysis[[outcome]]
  x = x[, -1]
  

  # call cv.glmnet()
  model_lasso <- cv.glmnet(x = x, y = y, alpha = 1)
  # plot(model_lasso)
  
  models_y1_use[[outcome]] <- model_lasso
  cc_y1_use = coef(model_lasso, s = model_lasso$lambda.min)
  print(model_lasso$lambda.min)

  # print out the model coefficients and store in a list.
  # exclude the intercept
  cc_y1_use = cc_y1_use[cc_y1_use[,1]!=0,1][-1]
  # remove backticks for ease of standardizing
  names(cc_y1_use)<- gsub("`","", names(cc_y1_use))
  coefficients_model_y1_use[[outcome]] <- cc_y1_use * allSd[names(cc_y1_use)]
  # print(cc)

}

## THESE ARE THE COEFFICIENTS FOR Y1: coefficients_model_y1_use
```


```{r}
# basic linear model (to get an idea of what to generate in simulation)
outcomes_and_obs_full_y1_largec_lm <- outcomes_and_obs_full_y1_largec %>%
  select(-c(caretype, actualtype, nsweeps.y, cid, classid, provid))

# summary(lm(as.formula(paste(outcomes_use_y1, "~ .")), 
#    data = outcomes_and_obs_full_y1_largec_lm))
```


```{r}
cv_glmmLasso <- function(data, formula, rand=list(j=~1),
                      lambda_step=20, lambda_min = lambda_min,
                      lambda_max = lambda_max) {
  lambdas <- seq(lambda_min, lambda_max, length = lambda_step)
  
  N <- nrow(data)
  ind <- sample(N, N)
  
  # number of folds
  
  kk <- 5
  nk <- floor(N/kk)
  
  pred_error <- matrix(NA, ncol=kk, nrow = lambda_step)

  
  for (j in 1:lambda_step) {
    for (i in 1:kk)
    {
      if (i < kk) {
      indi <- ind[(i-1)*nk+(1:nk)]
      }
      else {
      indi <- ind[((i-1)*nk+1):N]
      }
  
    data_train <- data[-indi,]
    data_test <- data[indi,]
  
    glm <- glmmLasso(fix = formula, rnd = rand, data = data_train, 
              lambda = lambdas[j]) 
    
    # glm <- try(glmmLasso(fix = formula, rnd = rand, data = data_train, 
    #       lambda = lambdas[j]), siilent = TRUE)
    
    return()
    
    print(j)
            
        # if(!inherits(glm, "try-error"))
        # {  
        #   y_hat <- predict(glm, data_test)  
        #   pred_error[j,i]<- sqrt(sum((data_test$Y - y_hat)^2) / nrow(data_test))
        # }
        # 
        # else 
        # {
        #   return("error in choosing lambda value")
        # }
    }
  }
  
  # find lambda which gives lowest prediction error
  pred_error_vec <- apply(pred_error, 1, sum)
  return(lambdas[which.min(pred_error_vec)])  
}

## other suggestion (haven't implemented this): run a simulation with a lot of lambdas, get a range of lambdas that we consistently see across these simulations. restrict the range based on those results
```



```{r}
lambda_range <- function(data, formula, p,
                         baseline_min_lambda = 10^(-2),
                         baseline_max_lambda = 10^3,
                         lambda_no = 20) {
    
    lambdas <- seq(baseline_min_lambda, baseline_max_lambda, length = lambda_no)
    min_lambda <- baseline_min_lambda
    max_lambda <- baseline_max_lambda
    coefs <- rep(0, lambda_no)
    
    for (l in 1:length(lambdas)) {
      print(l)
      mixed_lasso <- glmmLasso(fix = formula,
                           rnd=list(provid=~1),
                           data = data,
                           lambda = lambdas[l],
                           final.re = TRUE)
      
      coefs[l] <- sum(mixed_lasso$coefficients[2:(p + 1)] != 0)
                             
    }
    
    min_lambda <- ifelse(length(which(coefs == p)) == 0, 
                         baseline_min_lambda,
                         lambdas[max(which(coefs == p))])
    max_lambda <- ifelse(length(which(coefs == 0)) == 0,
                         baseline_max_lambda,
                         lambdas[min(which(coefs == 0))])
    return(c(min_lambda, max_lambda))
}
```

## row 1 on table of notes -- large_c with selection of variables

```{r}
## trying suggestion of using LASSO with very low regularization parameter
outcome <- outcomes_use_y1[1]
other_outcomes <- outcomes[outcomes != outcome]

data_processing <- function(data) {
  df_analysis_noncor <- data %>%
  filter(!is.na(data[[outcome]])) %>%
  dplyr::select(-c(all_of(other_outcomes), caretype, classid, 
                   cid, nsweeps.y,
                   actualtype, nsweeps.x)) 
  
  df_analysis_noncor <- as.data.frame(df_analysis_noncor)
  cor_matrix_largec <- cor(as.matrix(select_if(df_analysis, is.numeric)))
  cor_1 <- which(cor_matrix > 0.95, arr.ind = TRUE)
  cor_df <- as.data.frame(cor_1)
  cor_df$variables <- rownames(cor_1)
  rownames(cor_df) <- NULL
  high_corr <- cor_df[cor_df$row != cor_df$col, "variables"]

  df_analysis <- df_analysis_noncor %>%
    dplyr::select(-high_corr)
  
  return(df_analysis)
}

df_analysis_largec <- data_processing(outcomes_and_obs_full_y1_largec)
df_analysis_singleton <- data_processing(outcomes_and_obs_full_y1)
```


```{r}
pre_lasso <- function(data, fixed_lambda, mixed_lambdas = seq(0.01, 600, length = 20)) {
  options(na.action="na.pass")
  x = model.matrix(as.formula(paste(outcome, "~ . -provid")), 
                   data = data)
  
  y = data[[outcome]]
  x = x[, -1]
  
  model_lasso <- glmnet(x = x, y = y, lambda = fixed_lambda)
  coefs_for_glm <- coef(model_lasso)
  coefs_for_glm <- names(coefs_for_glm[coefs_for_glm[, 1] != 0, 1][-1])
  formula <- as.formula(paste(outcome, "~", paste(coefs_for_glm, 
                                                collapse = " + ")))
  predictive_coefs <- list()
  num_coefs <- list()

  for (i in 1:length(mixed_lambdas)) {
  mixed_lasso <- glmmLasso(data = data,
                           fix = formula, 
                           rnd = list(provid=~1),
                           lambda = mixed_lambdas[i])
  relevant_coefficients <- mixed_lasso$coefficients[2:(length(coefs_for_glm) + 1)]
  predictive_coefs[[i]] <- relevant_coefficients[relevant_coefficients != 0]
  num_coefs[[i]] <- length(relevant_coefficients)
  
  }
  
  return(list("coefficients" = predictive_coefs, 
              "coefficient_number" = num_coefs))
}

results_01_largec <- pre_lasso(df_analysis_largec, 0.1)
results_001_largec <- pre_lasso(df_analysis_largec, 0.01)

# results_01_singleton <- pre_lasso(x_singleton, y_singleton, 0.1)
# results_001_singleton <- pre_lasso(x_singleton, y_singleton, 0.01)

```


## row 2 on table of notes -- full data set (including singletons) with selection of variables

```{r}
coefs_non_prelasso <- colnames(df_analysis_largec)[! colnames(df_analysis_largec) %in% c("provid", outcome)]
formula_non_prelasso <-  as.formula(paste(outcome, "~", paste(coefs_non_prelasso, 
                                                collapse = " + ")))

glmmLasso(data = df_analysis_largec, fix = formula_non_prelasso, 
          rnd = list(provid=~1), lambda = 5)

glmmLasso(data = df_analysis_singleton, fix = formula_non_prelasso,
          rnd = list(provid=~1), lambda = 5)
```
## chose preprocessing method -- now comparing agreement?

## first method -- use the same lambda value that cv.glmnet (fixed) chooses

```{r}
all_vars <- colnames(df_analysis_largec)[! (colnames(df_analysis_largec) %in% c("provid", outcome))]
options(na.action="na.pass")
x = model.matrix(as.formula(paste(outcome, "~ . -provid")), 
                 data = df_analysis_largec)

y = df_analysis_largec[[outcome]]
x = x[, -1]

model_lasso <- glmnet(x = x, y = y, lambda = 0.1)
coefs_for_glm <- coef(model_lasso)
coefs_for_glm <- names(coefs_for_glm[coefs_for_glm[, 1] != 0, 1][-1])
formula <- as.formula(paste(outcome, "~", paste(coefs_for_glm, 
                                              collapse = " + ")))

fixed_lasso <- cv.glmnet(x, y, alpha = 1)
coefs_fixed <- coef(fixed_lasso, s = fixed_lasso$lambda.min)[-1]
nonzero_coefs_fixed <- which(coefs_fixed != 0)
nonzero_coefs_fixed <- all_vars[nonzero_coefs_fixed]

mixed_lasso <- glmmLasso(data = df_analysis_largec, fix = formula, 
                         rnd = list(provid=~1), lambda = fixed_lasso$lambda.min)
coefs_mixed <- mixed_lasso$coefficients[-1]
nonzero_coefs_mixed <- names(coefs_mixed[coefs_mixed != 0])

```


```{r}
# need to perform cross validation for both regular and glmmLasso
# citation link: https://davidabugaber.com/blog/f/find-the-optimal-mixed-model-for-your-data-with-glmmlasso


# only use three outcomes

# lambda <- 10^seq(-3,5, length=10)
# 
# BIC_vec <- rep(Inf, length(lambda))
# AIC_vec <- rep(Inf, length(lambda))
# Devianz_ma <- NULL
# Coeff_ma <- NULL

coefficients_model_y1_random <- list()
for (outcome in outcomes_use_y1) {
  other_outcomes <- outcomes[outcomes != outcome]
  df_analysis <- outcomes_and_obs_full_y1_largec %>%
    filter(!is.na(outcomes_and_obs_full_y1_largec[[outcome]])) %>%
    # make sure to not use cid, because it's basically just the row number at this point
    select(-c(other_outcomes, caretype)) %>%
    mutate_if(is.character, as.numeric) %>%
    mutate_at(vars(provid), factor) %>%
    select(-c("classid", "cid", "nsweeps.y")) %>%
    select(-ends_with("NA")) 
    # select(-starts_with(c("c_m8", "m_8")))
    # caretype, actualtype, classid,
    #           nsweeps.y, nadult, nclass, nsweeps.x)) %>%
    # select(-starts_with(c("c_m8", "m8", "o_c_verbal", "o_c_focus", "o_t_task"))) %>%
  
  var.names <- colnames(df_analysis)[-(which(colnames(df_analysis) 
                                             %in% c("provid", outcome,
                                                    "nsweeps.x")))]
  # var.names.abbrev <- var.names[1:17]
  # seems like the combination of var.names[18] with the previous 17
  # variables does not work well -- maybe they are too correlated?
  
  # for first outcome (may change, but that's currently # "gain_c_mefs_str")
  ## 1:17 works, but 1:18 does not
  ## 18:28 works, but 18:29 does 
  
  var.names.abbrev <- var.names[18:29]
  formula <- as.formula(paste(outcome, "~", paste(var.names.abbrev, collapse= " + ")))
  # placeholder lambda value
  # maybe lambda value is the issue?
  print(summary(glmmLasso(formula, rnd=list(provid=~1), data=df_analysis, 
                          lambda = 0.1, final.re = TRUE))) 
  break
  # models_y1_use[[name]] <- model_lasso
  # cc_y1_use = coef(model_lasso, s = model_lasso$lambda.min)

  # print out the model coefficients and store in a list.
  # exclude the intercept
  # cc_y1_use = cc_y1_use[cc_y1_use[,1]!=0,1][-1]
  # # remove backticks for ease of standardizing
  # names(cc_y1_use)<- gsub("`","", names(cc_y1_use))
  # coefficients_model_y1_use[[outcome]] <- cc_y1_use * allSd[names(cc_y1_use)]
  # print(cc)

}

```


```{r, fig.height=8, cache=TRUE, eval=FALSE}

for (i in gain_ind) {
  name
  hist(outcomes_and_obs_full_y1[, i])
}
```

```{r y1 pulling most predictive covariates, cache=TRUE}
# loop through the names associated with each outcome -- add 1 to corresponding entry
count_coefs_y1 <- list()
for (outcome in coefs_y1) {
  for (name in names(outcome)) {
    count_coefs_y1[[name]] <- ifelse(is.null(count_coefs_y1[[name]]), 1, 
                                     count_coefs_y1[[name]] + 1)
  }
}

#Convert output to a df for plotting and such
count_coefs_y1 <- count_coefs_y1 %>% 
  unlist() %>% 
  as.data.frame(row.names=TRUE)

count_coefs_y1$predictor <- row.names(count_coefs_y1)

names(count_coefs_y1) <- c("frequency", "predictor")
count_coefs_y1 <- count_coefs_y1[order(-count_coefs_y1$frequency), ]

# pull predictors that have more than 1 appearance

count_coefs_y1_top <- count_coefs_y1[count_coefs_y1$frequency > 1, ]
count_coefs_y1_top$outcomes <- rep(NA, nrow(count_coefs_y1_top))

list_store <- list()

for (top_predictor in count_coefs_y1_top$predictor) {
  for (i in 1:length(coefs_y1)) {
    outcome_name <- names(coefs_y1)[i]
    if (top_predictor %in% names(coefs_y1[[i]])) {
      if (is.null(list_store[[top_predictor]])) {
        list_store[[top_predictor]] <- list(outcome_name)
      }
      else {
        list_store[[top_predictor]] <- c(list_store[[top_predictor]], outcome_name)
      }
    }
  }
}
```


```{r y1 constructing binary data frame, cache=TRUE}
# all the unique outcomes that appear, so that they can be the columns in the
# binary table
unique_outcomes <- unique(unlist(unique(sapply(list_store, unlist))))
unique_predictors <- names(list_store)

# create data frame to translate into binary table
expand.grid(
  unique_predictors,
  unique_outcomes,
  stringsAsFactors = FALSE
) %>%
  set_names(c("predictors", "outcomes")) %>%
  mutate(value = rep(0, n())) -> binary_df

for (predictor in names(list_store)) {
  for (outcomes in list_store[[predictor]]) {
    outcomes_unlisted <- unlist(outcomes)
    for (outcome in outcomes_unlisted) {
        binary_df[binary_df$predictors == predictor & 
                    binary_df$outcomes == outcomes_unlisted, ]$value <- 1
    }
  }
}
```


```{r y1 making table, cache=TRUE}
mutate(
  binary_df,
  fill = ifelse(value == 1, "black", "white"),
  color = ifelse(value == 1, "white", "black"),
  address = factor(predictors, levels = sort(unique(predictors), decreasing = TRUE))
) -> cell_shading_df

ggplot(cell_shading_df, aes(x = outcomes, y = predictors)) +
  geom_tile(
    aes(fill = I(fill)),
    color = "#2b2b2b", size=0.125,
  ) +
  geom_text(
    aes(label = value, color = I(color))
  ) +
  scale_x_discrete(expand=c(0,0), position = "top") +
  scale_y_discrete(expand=c(0,0)) +
  labs(title = "Cell Shading Year 1", x = "outcomes", y = "predictors") +
  # hrbrthemes::theme_ipsum_rc(grid="XY") +
  theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=0.5))

```



```{r loop rf_test year1, echo=TRUE, fig.height=8, cache=TRUE, eval=FALSE}
varimp_y1 <- list()
rf_models <- list()
rf_plots <- list()
test_data <- outcomes_and_obs_full_y1

# make sure this works with small subset of data
for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y1)[i]
  df_analysis <- test_data %>%
    filter(!is.na(test_data[[name]])) %>%
    dplyr::select(c(name, "o_c_verbal_Fuss/Cry(FC)":actualtype))
    # ask about verbal_fuss vs o_c_verbal_Talk(T) (original)
    # mutate_at(vars("o_c_verbal_Fuss/Cry (FC)":actualtype), replace.na)
  print(name)
  # options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)

  # Fit the random forest model
  rf_fit <- train(as.formula(paste(name, "~ .")), #Use all variables in the prediction
                data = df_analysis, #Use the training data
                method = "ranger",
                importance = "permutation",
                # ntree = 500,
                na.action=na.pass)

  rf_plots[[name]] <- varImp(rf_fit) %>%
    pluck(1) %>%
    rownames_to_column("var") %>%
    ggplot(aes(x = reorder(var, Overall), y = Overall)) +
    geom_col(fill = "grey75") +
    coord_flip() +
    theme_minimal()

  # Store the full RF model
  rf_models[[name]] <- rf_fit

  # store variable importances as a data frame
  df <- as.data.frame(varImp(rf_fit)$importance)
  # arrange in descending order (most to least important), and put into list
  varimp_y1[[name]] <- df %>% arrange(desc(Overall))
}

rfoutput <- list(varimp_y1, rf_models, rf_plots)

saveRDS(rfoutput, file = "rfoutput.RDS")


```



```{r next steps}
#NOTES FROM MEETINGI 8/8
#1. Try Y2 observation data instead of Y1, and compare results
#2. Try a model with a bunch of predictors from Y1 Y2 -- looking at more demographic variables
# wait for Jonathan to see which demographic variables are important
#3. Use the particular caretype from the  setting that is being observed in. (prov_type)
#Collapse CC-Community Based & CC- License Exempt -- 
#4. Include leave-out standard deviation for each predictor as well
#5. Incorporte child-level covariates -- wait for this one as well
#6. Age and elapsed time for assessment 
# look for date in the cleaning process -- flag it and let Jonathan take closer look

## 4 is a priority, plus other things we discussed (on google doc)

# comparing random forest and lasso results -- scatter the absolute value of coefficients (double check if both are standardized -- if not, adjust!) -- each point is a predictor 
# should hopefully see some 
```

```{r}
# As far as I can tell, variable importance is measuring either: a) the percentage that the prediction error increases when the variable is removed, or b) the change in the purity of each node when the variable is removed. (Averaged over all trees in the forest.) Neither of these is a probability, so there's no reason they should add up to 100%.

# I'm not sure if I will try to "unstandardize" the random forest results. I will use the magnitude of the coefficients as a proxy for "variable importance," and scatter that against the variable importance (when variables are present in  both variable selection methods)

# todo:
# 1. extract coefficient values for each selected variable from lasso - maybe store in data frame?
# 2. find a way to extract numeric value of variable importance - also store in data frame
# 3. merge data frames -- thinking one data frame per variable? so list of data frames
# 4. scatter values against each other

```


```{r merge.obs.outcomes y2 p1, cache=TRUE}
#Merge in the outcomes data 
#  Try Y2 observation data instead of y1, and compare results

# add this line in so that the merge is correctly executed

y2_obs <- y2_obs %>%
  filter(!is.na(cid)) %>%
  mutate(cid = as.numeric(cid))

outcomes_and_obs_y2 <- left_join(child_outcomes, y2_obs, by = "cid") %>% 
  mutate(cid = as.character(cid))

#Add in the care type -- confirm that it is supposed to be year-specific
caretype <- read.dta13("y2caretype.dta", nonint.factors = TRUE) %>% 
  mutate(cid = as.character(cid))

#Remove observations that have no care type or no classroom observation
outcomes_and_obs_full_y2 <- left_join(outcomes_and_obs_y2, caretype, by = "cid") %>% 
  mutate(hasobservation = is.na(classid)) %>% 
  filter(!is.na(caretype)) %>%
  filter(!is.na(classid))

# outcomes_and_obs_full_y1 <- outcomes_and_obs %>% 
#   filter(!is.na(classid))

#Remove Y1 and Y2 data for cleanliness
outcomes_and_obs_full_y2 <- outcomes_and_obs_full_y2 %>% 
  dplyr::select(-starts_with(c("y1", "y2")))

#Remove some irrelevant variables and remove illegal spaces
outcomes_and_obs_full_y2 <- outcomes_and_obs_full_y2 %>% 
  # seems like provid is the same thing as famid in this case?
  dplyr::select(-c(provid, dob, actualtype_fcc:hasobservation)) %>% 
  mutate(caretype = as.factor(caretype),
         actualtype = as.factor(actualtype)) %>% 
  rename_at(vars(everything()), ~str_replace_all(., "\\s+", ""))

```


```{r merge.obs.outcomes y2 p2, cache=TRUE}

outcomes_and_obs_full_y2 <- outcomes_and_obs_full_y2 %>% 
  mutate_at(vars("o_c_verbal_Fuss/Cry(FC)":actualtype), replace.na)

dim(outcomes_and_obs_full_y2)
```

## Analysis

We will first try a cross-validated LASSO, which will aggressively remove variables that do little to improve the predictive accuracy of the model.  

```{r loop lasso y2, echo=TRUE, fig.height=8, cache=TRUE}
set.seed(4224)

gain_ind <- which(startsWith(colnames(outcomes_and_obs_full_y2), "gain"))

models_y2 <- list()
coefs_y2 <- list()

for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y2)[i]
  df_analysis <- outcomes_and_obs_full_y2 %>%
    filter(!is.na(outcomes_and_obs_full_y2[[name]])) %>%
    dplyr::select(c(name, "o_c_verbal_Fuss/Cry(FC)":actualtype))
  allSd <- apply(df_analysis[, -i], 2, sd)
  print(name)
  options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)
  
  y = df_analysis[[name]]
  print(dim(x))
  x = x[, -1]
  

  # call cv.glmnet()
  model_lasso <- cv.glmnet(x = x, y = y, alpha = 1)
  plot(model_lasso)
  plot(model_lasso$glmnet.fit, "lambda", main=name)
  
  models_y2[[name]] <- model_lasso
  
  cc = coef(model_lasso, s = model_lasso$lambda.min)

  # print out the model coefficients and store in a list.
  cc = cc[cc[,1]!=0,1][-1]
  # remove backticks for ease of standardizing
  names(cc)<- gsub("`","", names(cc))
  coefs_y2[[name]] <- cc * allSd[names(cc)]
}
```

```{r y2 pulling most predictive covariates, cache=TRUE}
# loop through the names associated with each outcome -- add 1 to corresponding entry
count_coefs_y2 <- list()
for (outcome in coefs_y2) {
  for (name in names(outcome)) {
    count_coefs_y2[[name]] <- ifelse(is.null(count_coefs_y2[[name]]), 1, 
                                     count_coefs_y2[[name]] + 1)
  }
}

#Convert output to a df for plotting and such
count_coefs_y2 <- count_coefs_y2 %>% 
  unlist() %>% 
  as.data.frame(row.names=TRUE)

count_coefs_y2$predictor <- row.names(count_coefs_y2)

names(count_coefs_y2) <- c("frequency", "predictor")
count_coefs_y2 <- count_coefs_y2[order(-count_coefs_y2$frequency), ]

# pull predictors that have more than 1 appearance

count_coefs_y2_top <- count_coefs_y2[count_coefs_y2$frequency > 1, ]
count_coefs_y2_top$outcomes <- rep(NA, nrow(count_coefs_y2_top))

list_store <- list()

for (top_predictor in count_coefs_y2_top$predictor) {
  for (i in 1:length(coefs_y2)) {
    outcome_name <- names(coefs_y2)[i]
    if (top_predictor %in% names(coefs_y2[[i]])) {
      if (is.null(list_store[[top_predictor]])) {
        list_store[[top_predictor]] <- list(outcome_name)
      }
      else {
        list_store[[top_predictor]] <- c(list_store[[top_predictor]], outcome_name)
      }
    }
  }
}
```


```{r y2 constructing binary data frame, cache=TRUE}
# all the unique outcomes that appear, so that they can be the columns in the
# binary table
unique_outcomes <- unique(unlist(unique(sapply(list_store, unlist))))
unique_predictors <- names(list_store)

# create data frame to translate into binary table
expand.grid(
  unique_predictors,
  unique_outcomes,
  stringsAsFactors = FALSE
) %>%
  set_names(c("predictors", "outcomes")) %>%
  mutate(value = rep(0, n())) -> binary_df

for (predictor in names(list_store)) {
  for (outcomes in list_store[[predictor]]) {
    outcomes_unlisted <- unlist(outcomes)
    for (outcome in outcomes_unlisted) {
        binary_df[binary_df$predictors == predictor & 
                    binary_df$outcomes == outcomes_unlisted, ]$value <- 1
    }
  }
}
```


```{r y2en making table, cache=TRUE}
mutate(
  binary_df,
  fill = ifelse(value == 1, "black", "white"),
  color = ifelse(value == 1, "white", "black"),
  address = factor(predictors, levels = sort(unique(predictors), decreasing = TRUE))
) -> cell_shading_df

ggplot(cell_shading_df, aes(x = outcomes, y = predictors)) +
  geom_tile(
    aes(fill = I(fill)),
    color = "#2b2b2b", size=0.125,
  ) +
  geom_text(
    aes(label = value, color = I(color))
  ) +
  scale_x_discrete(expand=c(0,0), position = "top") +
  scale_y_discrete(expand=c(0,0)) +
  labs(title = "Cell Shading Year 2", x = "outcomes", y = "predictors") +
  # hrbrthemes::theme_ipsum_rc(grid="XY") +
  theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=0.5))

```


```{r loop rf_test y2, echo=TRUE, fig.height=8, cache=TRUE, eval=FALSE}

varimp_y2 <- list()
# NOTE: change to full data set here
test_data <- head(outcomes_and_obs_full_y2, 100)
# make sure this works with small subset of data
for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y2)[i]
  df_analysis <- test_data %>%
    filter(!is.na(test_data[[name]])) %>%
    dplyr::select(c(name, "o_c_verbal_Fuss/Cry(FC)":actualtype)) 
    # ask about verbal_fuss vs o_c_verbal_Talk(T) (original)
    # mutate_at(vars("o_c_verbal_Fuss/Cry (FC)":actualtype), replace.na)
  print(name)
  # options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)
  
  # Fit the random forest model
  rf_fit <- train(as.formula(paste(name, "~ .")), #Use all variables in the prediction
                data = df_analysis, #Use the training data
                method = "ranger",
                importance = "permutation",
                # ntree = 500,
                na.action=na.pass)
                
  varImp(rf_fit) %>%
    pluck(1) %>%
    rownames_to_column("var") %>%
    ggplot(aes(x = reorder(var, Overall), y = Overall)) +
    geom_col(fill = "grey75") +
    coord_flip() +
    theme_minimal()
  
  # store variable importances as a data frame
  df <- as.data.frame(varImp(rf_fit)$importance)
  # arrange in descending order (most to least important), and put into list
  varimp_y2[[name]] <- df %>% arrange(desc(Overall))
}
```


```{r comparison year2, echo=TRUE, fig.height=8, cache=TRUE, include=FALSE}
outcomes <- names(outcomes_and_obs_full_y2)[gain_ind]

for (outcome in outcomes) {
  # print(outcome)
  lasso_coefs <- coefs_y2[[outcome]]
  # get rid of intercept
  if (length(lasso_coefs) == 1) {
    next
  }
  lasso_coefs <- lasso_coefs[2:length(lasso_coefs)]
  rf_coefs <- varimp_y2[[outcome]]
  # this will be in the order of the coefficients in the lasso model
  overlap <- rf_coefs[names(lasso_coefs),]
  x <- rep(NA, length(lasso_coefs))
  for (i in 1:length(lasso_coefs)) {
    x[i] <- abs(lasso_coefs[[i]])
  }
  plot(x, overlap, xlab='lasso coefficients', ylab='rf variable importance', main=paste('y2', outcome))
}
```


```{r read rds obj, include=FALSE}
# rfoutput <- list(varimp_y1, rf_models, rf_plots)
rf_y1_obj <- readRDS('/Users/thupham/Desktop/elsah-coptop/rfoutput.RDS')
```

```{r actual outcomes, cache=TRUE, include=FALSE}
proper_names <- list()
proper_names[["gain_c_mefs_str"]] <- "MEFS Z-score"
proper_names[["gain_c_pt_pcorrect"]] <- "Pencil Tap"
proper_names[["gain_c_ltr_cogsoc_comp"]] <- "Leiter - Cognitive/Social"
proper_names[["gain_c_ltr_emo_comp"]] <- "Leiter - Emotions/Regulation"
proper_names[["gain_c_pbsa_total"]] <- "PALS BSA"
proper_names[["gain_c_pra_total"]] <- "PALS RA"
proper_names[["gain_c_quils_total_raw"]] <- "QUILS"
proper_names[["gain_c_wjlw_str"]] <- "WJ Letter Word ID"
proper_names[["gain_c_wjap_str"]] <- "WJ Applied Problems"
```


```{r comparison year1, echo=TRUE, fig.height=8, cache=TRUE}
# comparing lasso and random forest results, for year 1
outcomes <- names(outcomes_and_obs_full_y1)[gain_ind]
varimp_y1 <- rf_y1_obj[[1]]
comparison_df <- data.frame(matrix(ncol = 4, nrow = 0))

for (outcome in outcomes) {
  # print(outcome)
  lasso_coefs <- coefs_y1[[outcome]]
  # get rid of intercept
  if (length(lasso_coefs) == 0) {
    next
  }
  lasso_coefs <- lasso_coefs[2:length(lasso_coefs)]
  rf_coefs <- varimp_y1[[outcome]]
  # removing illegal characters for consistency
  row.names(rf_coefs) <- gsub(" ", "", row.names(rf_coefs))
  row.names(rf_coefs) <- gsub("`", "", row.names(rf_coefs))
  # this will be in the order of the coefficients in the lasso model
  overlap <- rf_coefs[names(lasso_coefs),]
  x <- rep(NA, length(lasso_coefs))
  for (i in 1:length(lasso_coefs)) {
    x[i] <- abs(lasso_coefs[[i]])
  }
  comparison_df <- rbind(comparison_df, cbind(x, overlap, 
                                              rep(outcome, length(x)),
                                              rep(proper_names[[outcome]],
                                                  length(x))))
}

comparison_df <- comparison_df %>% 
  rename("lasso" = "x", "rf" = "overlap", "gains" = "V3", "outcome"=V4) %>%
  mutate_at(vars(lasso, rf), as.numeric)

## TO DO: need to pull the actual names of the outcomes for better plot titles
ggplot(comparison_df, aes(lasso, rf, color = outcome)) +
  geom_point() +
  facet_wrap(~outcome) +
  geom_smooth(method='lm') + 
  theme(legend.position="none") + 
  labs(title="Year 1 Comparison of Lasso and Random Forest",
       x ="Standardized Lasso Coefficients", 
       y = "Random Forest Variable Importance") + 
  theme(plot.title = element_text(hjust = 0.5))

```


```{r variable_importance y1, cache=TRUE}
var_imp_y1 <- rf_y1_obj[[1]]
for (name in names(var_imp_y1)) {
  varimp_df <- head(var_imp_y1[[name]], 10)

  row.names(varimp_df) <- gsub(" ", "", row.names(varimp_df))
  row.names(varimp_df) <- gsub("`", "", row.names(varimp_df))
  varimp_df$predictors <- row.names(varimp_df)
  
  plot <- ggplot(varimp_df, aes(x=reorder(predictors, +Overall), y=Overall)) +
    geom_col() +
    coord_flip() + 
    labs(title=paste(proper_names[[name]], 
                     "Random Forest Variable Importance"),
       x ="Predictors", 
       y = "Variable Importance") + 
    theme(plot.title = element_text(size = 10),
          axis.title = element_text(size = 10),
          axis.text.y = element_text(size = 5),
          axis.text.x = element_text(size = 5))
  print(plot)
}

```

